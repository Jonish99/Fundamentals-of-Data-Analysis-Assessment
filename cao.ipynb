{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e8b6b3-4d32-44c2-a85f-e6da35747375",
   "metadata": {},
   "source": [
    "# A demonstration of PANDAS data frames used to investigate CAO points\n",
    "\n",
    "Author: Jon Ishaque\n",
    "Commenced: 29th September 2021\n",
    "GMIT SID: G00398244\n",
    "\n",
    "This notebook extracts CAO points from the CAO website for 2019, 2020 and 2021. It loads data into pandas dataframes and uses pandas and python to compare points from different years.\n",
    "\n",
    " Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    " \n",
    " \n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d53c1a-1d21-4ccf-8409-8e7480bf2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Package to make http requests\n",
    "#(Requests: HTTP for Humans™ — Requests 2.26.0 documentation, 2021)\n",
    "import requests as rq \n",
    "\n",
    "# Dates and time package (installed with python)\n",
    "import datetime as dt\n",
    "\n",
    "#pandas to load data into dataframes and use functionality to manipulate data and analyse data\n",
    "import pandas as pd\n",
    "\n",
    "#import regex package for searching strings (installed with python)\n",
    "#(re — Regular expression operations — Python 3.10.0 documentation, 2021)\n",
    "import re \n",
    "\n",
    "#import csv, deals with commas when writing to file\n",
    "import csv\n",
    "\n",
    "#use urlib to retrieve url as file for 2019 and 2020   (installed with python)\n",
    "import urllib.request as urlrq \n",
    "\n",
    "#Python plotting package\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#camelot pdf file reader package\n",
    "import camelot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717922c-6643-4593-a1fb-5814f3f194e6",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. Loading CAO data into pandas.\n",
    "\n",
    "Loading data into the notebook and pandas dataframes requires 3 different methods for each of the years 2019, 2020 and 2021 because for each year the data is in a different format:\n",
    "\n",
    "2021 html webpage format\n",
    "\n",
    "2020 Microsoft Excel format\n",
    "\n",
    "2019 pdf\n",
    "\n",
    "The next state of the notebook will explain how each years CAO points are accessed from the CAO website, backed up locally in their original format and imported into a pandas dataframe for each year either directly or from a saved csv..\n",
    "\n",
    "The dataframes for each year are then joined up (1.4).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336fefee-76de-43b1-b5f3-377fcd3f791d",
   "metadata": {},
   "source": [
    "*** \n",
    "### 1.1 2021 points\n",
    "\n",
    "#http://www.cao.ie/index.php?page=points&p=2021\n",
    "\n",
    "The 2021 CAO points are presented in a web page. \n",
    "There are two pages one for level 6 & 7 and one for level 8.\n",
    "The web page are saved and files and loaded into a dataframe. \n",
    "\n",
    "The function get2021() \n",
    "reads a webpage  accessed using the request library.\n",
    "Each line of the web page is read and tested for CAO course and points line\n",
    "with a regex. There are helper functions atomise fields into characters which may indicate, random selections and portfolio/interview assessment for courses. There is also a function to determing the institution form the course code. Each line is then written to a csv file.\n",
    "\n",
    "Both the level 6 & 7 and level 8 are then loaded into a single dataframe df2021\n",
    "\n",
    "The page header from the server should decode as per: *Content-Type: text/html; charset=iso-8859-1*\n",
    "However, one line uses \\x96 which isn't defined in iso-8859-1. Therefore we use the similar decoding standard cp1252, which is very similar but includes #x96. The character in question was had an Irish foda on a level 8 course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace62ef-a7fc-4ecb-a031-85025c2fd75d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1670e56-6d1f-41e0-82ab-48192b915c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date and time.\n",
    "#Create a string var,*now*. this is use in file names of back up copies of CAO points.\n",
    "now = dt.datetime.now()\n",
    "\n",
    "# Format as a string.\n",
    "#global as used in functions\n",
    "global nowstr\n",
    "nowstr = now.strftime('%Y%m%d_%H%M%S')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1c050-a5d7-435b-9a47-843528f77676",
   "metadata": {},
   "source": [
    "Compile the regular expression so it is not compiled at each interation of the loop reading the webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aaa91d-c89c-4a91-a669-e0e5829be163",
   "metadata": {},
   "source": [
    "Explanation of the regualar expression (re — Regular expression operations — Python 3.10.1 documentation, 2021):\n",
    "\n",
    "**('&#91;A-Z]{2}&#91;0-9&#93;{3} (.*)(&#91;0-9&#93;{3})')**\n",
    "\n",
    "\n",
    "&#91;A-Z&#93;{2}           Any two upper case aphanumeric\n",
    "\n",
    "&#91;0-9&#93;{3}           Any three digits 0-9\n",
    "\n",
    "'  '                       Two spaces\n",
    "\n",
    "(.*)(&#91;0-9&#93;{3})     Any amount of text before 3 numeric characters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e78b1faf-cb9c-4494-9a9c-f19b73739946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set reg ex\n",
    "re_courses = re.compile('[A-Z]{2}[0-9]{3} (.*)') \n",
    "#(re — Regular expression operations — Python 3.10.1 documentation, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a4f57be-a30d-4221-94a5-610a6d31fb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to get HEI name from course code. using a switcher dict as\n",
    "#oppose to messy if/else block\n",
    "#(How to Implement Switch Case Functions in Python? [2021] | upGrad blog, 2021)\n",
    "def getHEI(cc):\n",
    "    switcher = {'AC' : 'American College',\n",
    "    'AD' : 'National College of Art and Design',\n",
    "    'AL' : 'Athlone Institute of Technology',\n",
    "    'AS' : 'St. Angela`s College',\n",
    "    'CI' : 'Irish College of Humanities & Applied Sciences',\n",
    "    'BY' : 'IBAT College Dublin',\n",
    "    'BN' : 'Technological University Dublin Blanchardstown Campus',\n",
    "\n",
    "    'CK' : 'University College Cork (NUI)',\n",
    "    'CM' : 'Marino Institute of Education',\n",
    "    'CR' : 'Cork Institute of Technology',\n",
    "    'CT' : 'CCT College Dublin',\n",
    "    'CW' : 'Institute of Technology Carlow',\n",
    "    'DB' : 'Dublin Business School',\n",
    "    'DC' : 'Dublin City University',\n",
    "    'DK' : 'Dundalk Institute of Technology',\n",
    "    'DL' : 'Dun Laoghaire Institute of Art Design and Technology',\n",
    "    'DT' : 'Technological University Dublin City Campus',\n",
    "    'TA' : 'Technological University Dublin Tallaght Campus',\n",
    "    'DN' : 'University College Dublin (NUI)',\n",
    "    'DS' : 'Dorset College',\n",
    "    'GA' : 'Galway-Mayo Institute of Technology',\n",
    "    'GB' : 'Galway Business School',\n",
    "    'GC' : 'Griffith College',\n",
    "    'GY' : 'National University of Ireland Galway',\n",
    "    'ID' : 'ICD Business School',\n",
    "    'LC' : 'Limerick Institute of Technology',\n",
    "    'LM' : 'University of Limerick',\n",
    "    'LY' : 'Letterkenny Institute of Technology',\n",
    "    'MH' : 'Maynooth University',\n",
    "    'MI' : 'Mary Immaculate College',\n",
    "    'MU' : 'Pontifical University St Patricks College',\n",
    "    'NC' : 'National College of Ireland (NCI)',\n",
    "    'NM' : 'St Nicholas Montessori College Ireland',\n",
    "    'PC' : 'Carlow College St. Patricks',\n",
    "    'RC' : 'RCSI University of Medicine & Health Sciences',\n",
    "    'SG' : 'Institute of Technology Sligo',\n",
    "    'TL' : 'Institute of Technology Tralee',\n",
    "    'TR' : 'Trinity College Dublin',\n",
    "    'TU' : 'Technological University Dublin',\n",
    "    'WD' : 'Waterford Institute of Technology'\n",
    "    }\n",
    "    cc = cc[:2]\n",
    "    return  switcher.get(cc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68bc80e0-02ce-43e7-a4be-75fc94bc72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to AQA,* and # indicators from points values\n",
    "def points_to_arr(s):\n",
    "    AQA=''\n",
    "    portfolio =''\n",
    "    points=''\n",
    "    random = ''\n",
    "    #check 1st char for #\n",
    "    #print(s)\n",
    "    if s[0]=='#':\n",
    "        portfolio='#'# add to var\n",
    "    #check final char for  *\n",
    "    if s[-1] == '*':\n",
    "        random ='*'\n",
    "    points=''    \n",
    "    if s.find('AQA') ==-1: #not AQA\n",
    "        #strip ~ and * from start and end of s\n",
    "        for i in s:\n",
    "            if i.isdigit():\n",
    "                #concat points string\n",
    "                points = points + i\n",
    "    else:\n",
    "        AQA =\"AQA\" #return AQA as separate val as it will be separate column\n",
    "        #return\n",
    "    return [points, portfolio, random,AQA]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f644b8-b265-4f9f-99f2-b1f1d2060fbb",
   "metadata": {},
   "source": [
    "This part of the note part of the note book will load the web page content. A loop will read each line of web page and determine if it's content is relevant and write content to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a69844e-746d-4123-a633-6417ccb8f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global csv path list so the programme\n",
    "#will find the csv files after function\n",
    "global csv_files\n",
    "csv_files = []\n",
    "def get2021(path): #A function to create csv files from both the L6&7 and L8 webpages.\n",
    "    #Get the both level 8 and 6/7 web pages\n",
    "    #getheaders and determine contenttype\n",
    "    #loop through response text lines\n",
    "    #get level\n",
    "    #print (path)\n",
    "    if path.find('L8') >= 0 :\n",
    "        level = '8'\n",
    "        resp = rq.get('http://www2.cao.ie/points/l8.php',\n",
    "                      headers={\"content-type\":\"text\"})\n",
    "    elif path.find('L67') >= 0 :\n",
    "        level ='6/7'        \n",
    "        resp = rq.get('http://www2.cao.ie/points/l76.php', \n",
    "                      headers={\"content-type\":\"text\"})\n",
    "    else:\n",
    "        level = ''        \n",
    "    original_encoding = resp.encoding\n",
    "    # Change to cp1252, which handles accented characters\n",
    "    resp.encoding = 'cp1252'\n",
    "    # Create a file path for the original data. 2021\n",
    "    pathhtml = path + nowstr + '.html'\n",
    "    # Save the original html file.\n",
    "    with open(pathhtml, 'w') as f:\n",
    "        f.write(resp.text)\n",
    "    #set var to count lines for cross check with webpage\n",
    "    no_lines = 0\n",
    "    path = path+'.csv'\n",
    "    #add csv name to array so as to access when loading into df\n",
    "    csv_files.append(path)\n",
    "    with open(path, 'w') as f:\n",
    "        #write csv header\n",
    "        '''\n",
    "        PREFIXES:\n",
    "        R1 = Round 1 points\n",
    "        *     Not all on this points score were offered places.\n",
    "        #     Test / Interview / Portfolio / Audition\n",
    "        AQA   All qualified applicants\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        linesplit = ['Course Code','Course title','R1',\n",
    "                     'Po1','Rn1','AQA1','R2',\n",
    "                     'Po2','Rn2','AQA2',\n",
    "                     'HEI','Level','Year']\n",
    "        f.write(','.join(linesplit) + '\\n')\n",
    "        #loop through each line of csv and do something.\n",
    "        for line in resp.iter_lines():\n",
    "            #problem with bytes so convert str to bytes\n",
    "            dline = line.decode('cp1252')\n",
    "            #check if line mathces reg exp pattern. If so, do something.\n",
    "            if re_courses.fullmatch(dline):\n",
    "                no_lines +=1\n",
    "                #get first five chars - course code\n",
    "                course_code = dline[:5]\n",
    "                \n",
    "                #course title\n",
    "                course_title = dline[7:57]\n",
    "                #r1 points\n",
    "                round_1 = dline[60:65].rstrip() # get five chars, remove white space\n",
    "                #if round 1 not blank call fn points_to_arr\n",
    "                if len(round_1) > 0:\n",
    "                   \n",
    "                    round_1= points_to_arr(round_1)\n",
    "                    #assign vals from returned array\n",
    "                    pts1 = round_1[0]\n",
    "                    plo1 = round_1[1]\n",
    "                    rnd1 = round_1[2]\n",
    "                    AQA1 = round_1[3]\n",
    "                else: \n",
    "                    pts1 = ''\n",
    "                    plo1 = ''\n",
    "                    rnd1 = ''\n",
    "                    AQA1 = ''\n",
    "                #r2 points\n",
    "                round_2 = dline[67:].rstrip() # get four chars, remove white space\n",
    "                #if round 2 not blank call fn points_to_arr\n",
    "                if len(round_2) > 0:\n",
    "                    round_2= points_to_arr(round_2)\n",
    "                    #assign vals from returned array\n",
    "                    pts2 = round_2[0]\n",
    "                    plo2 = round_2[1]\n",
    "                    rnd2 = round_2[2]\n",
    "                    AQA2 = round_2[3]\n",
    "                else: \n",
    "                    pts2 = ''\n",
    "                    plo2 = ''\n",
    "                    rnd2 = ''\n",
    "                    AQA2 = ''\n",
    "                #print (course_code)\n",
    "                #get the instituion name\n",
    "                HEI =getHEI(course_code)\n",
    "                #print (HEI)\n",
    "                # create an array of the fields for the csv line\n",
    "                linesplit = [course_code,course_title,pts1,plo1,rnd1,AQA2,pts2,plo2,rnd2,AQA2,HEI,level,'2021']\n",
    "                #print (linesplit)\n",
    "                #debug\n",
    "                #print(f\"'{course_code} {dline} r1: {round_1} r2: {round_2}'\")\n",
    "                # print((','.join(linesplit) + '\\n'))\n",
    "                # Rejoin the array values with commas in between. ie.comma separated\n",
    "                f.write(','.join(linesplit) + '\\n')\n",
    "    print (f\"{path}number of lines is \", {no_lines}) #print file path and number of lines as confirmation\n",
    "    path=''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d0cf45-688d-444e-ac86-f2641099feec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The file path for the csv file.\n",
    "path_2021_L8 = 'data/cao2021_L8_' + nowstr \n",
    "path_2021L67 ='data/cao2021_L67_' + nowstr \n",
    "\n",
    "#call the get2021 function with paths to save the html file and create a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "849d2759-6103-4ae1-bad6-575f6dd076ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cao2021_L8_20220102_110721.csvnumber of lines is  {949}\n",
      "data/cao2021_L67_20220102_110721.csvnumber of lines is  {416}\n"
     ]
    }
   ],
   "source": [
    "get2021(path_2021_L8)\n",
    "get2021(path_2021L67)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c583d24-c845-47cd-a4a3-7daebabcf2f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "NB: 949 L8 courses on CAO website verified on 10th November 2021\n",
    "\n",
    "416 L6/7 courses on CAO website verified on 15th November 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ea660-9a7c-436b-a22b-43dcca743b9a",
   "metadata": {},
   "source": [
    "Join L8 & L6/7 courses into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fa70f32-034d-43a6-94e0-ebbbc9397a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/cao2021_L8_20220102_110721.csv', 'data/cao2021_L67_20220102_110721.csv']\n"
     ]
    }
   ],
   "source": [
    "# loop over the list of csv files (Pandas, 2021)\n",
    "print(csv_files)\n",
    "df2021 = pd.DataFrame()\n",
    "for f in csv_files:      \n",
    "    # read the csv file with correc encoding\n",
    "    #print(f)\n",
    "    df_temp = pd.read_csv(f,encoding='cp1252') \n",
    "    \n",
    "    #create a dataframe with all 2021 data\n",
    "    df2021 = df2021.append(df_temp, ignore_index = True)\n",
    "\n",
    "#debug\n",
    "#print(df2021)\n",
    "df2021.to_csv('data/2021.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a372d87-ba83-4a1c-9176-f61e5ca57396",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e55352-cc54-464f-95fe-3f46ccd224f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 2020 CAO points\n",
    "\n",
    "http://www.cao.ie/index.php?page=points&p=2020 \n",
    "\n",
    "The CAO points for 2020 stored in an excel(.xls) file. All level courses were indcluded in the one file\n",
    "The excel file is downloaded using the urlrq package and backed up.\n",
    "The file is read then downloaded into a  pandas data frame df2020.\n",
    "\n",
    "Some unwanted columns are deleted and columns are renamed for consistency with other years.\n",
    "*, AQA and # indicators are pulled out using pandas functionality and written to new columns.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "359f5ab1-0128-41c5-8c24-fbc883961b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/cao2020_20220102_110721.xlsx',\n",
       " <http.client.HTTPMessage at 0x1b9aee86b20>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a file path for the original data.For backup\n",
    "path2020 = 'data/cao2020_' + nowstr + '.xlsx'\n",
    "\n",
    "#download to path\n",
    "urlrq.urlretrieve('http://www2.cao.ie/points/CAOPointsCharts2020.xlsx',\\\n",
    "                  path2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421cad63-4081-4846-9530-23f1a8cd2dd7",
   "metadata": {},
   "source": [
    "Read the Excel file into a pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "421461f9-e63a-4423-a92b-8ec6241194aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and parse the excel spreadsheet\n",
    "#skip first 10 header rows\n",
    "#(pandas.read_excel — pandas 1.3.4 documentation, 2021)\n",
    "df2020=pd.read_excel('http://www2.cao.ie/points/CAOPointsCharts2020.xlsx',\\\n",
    "                 skiprows=10)\n",
    "#delete unwanted columns\n",
    "df2020 = df2020.drop(['CATEGORY (i.e.ISCED description)','avp','v','Column1',\\\n",
    "              'Column2','Column3','Column4','Column5','Column6',\\\n",
    "              'Column7','Column8','Test/Interview #','EOS Random *'], 1)\n",
    "#rename columns \n",
    "df2020 = df2020.rename(columns={'COURSE TITLE': 'Course title',\\\n",
    "                        'COURSE CODE2': 'Course Code',\\\n",
    "                        'R1 POINTS':'R1','R2 POINTS':'R2',\\\n",
    "                        'R1 Random *':'Rn1',\\\n",
    "                        'R2 Random*':'Rn2','LEVEL':'Level',\\\n",
    "                        'EOS':'EOS','EOS Mid-point':'Mid'})\n",
    "#add some new columns so we will match our 2021 dataframe\n",
    "df2020['Year'] =2020\n",
    "df2020['Po1'] =''\n",
    "df2020['Po2'] =''\n",
    "df2020['AQA1'] =''\n",
    "df2020['AQA2'] =''\n",
    "\n",
    "#Pulling out AQA, # and  placing into own column.\n",
    "#this dataset has either digits or #matric code for portfolio and AQA. Check for value,\n",
    "#if it exists place in another column and set points col to blank.\n",
    "#(Check For a Substring in a Pandas DataFrame Column, 2021)\n",
    "df2020.loc[df2020['R1'].str.contains('#',na=False) ,'Po1'] = '#'  \n",
    "#df2020.loc[df2020['R1'].str.contains('#',na=False) ,'Po1'] = '#' \n",
    "df2020.loc[df2020['R2'].str.contains('#',na=False) ,'Po2'] = '#' \n",
    "df2020.loc[df2020['R1'].str.contains('AQA',na=False) , 'AQA1'] = 'AQA' \n",
    "df2020.loc[df2020['R2'].str.contains('AQA',na=False) , 'AQA2'] = 'AQA' \n",
    "#set to blank data which are either not needed or have been processed above\n",
    "df2020.loc[df2020['EOS'].str.contains('matric',na=False) , 'EOS'] = '' \n",
    "df2020.loc[df2020['Mid'].str.contains('matric',na=False) , 'Mid'] = '' \n",
    "df2020.loc[df2020['R1'].str.contains('matric',na=False) , 'R1'] = '' \n",
    "df2020.loc[df2020['R1'].str.contains('AQA',na=False) , 'R1'] = ''\n",
    "df2020.loc[df2020['R2'].str.contains('matric',na=False) , 'R2'] = '' \n",
    "df2020.loc[df2020['R2'].str.contains('AQA',na=False) , 'R2'] = '' \n",
    "\n",
    "#Need to clean '#' from points\n",
    "#convert to string to use replace function\n",
    "df2020['R1'] = df2020['R1'].astype(str) #(pandas and Riley, 2021)\n",
    "df2020['R1'] = df2020['R1'].map(lambda x: x.replace('#',''))\n",
    "df2020['R1'] = df2020['R1'].map(lambda x: x.lstrip('nan'))#remove nan to convert back to number('int', 2021)\n",
    "df2020['R1'] = pd.to_numeric(df2020['R1'], errors='coerce')#back to numeric\n",
    "#and round 2 points\n",
    "df2020['R2'] = df2020['R2'].astype(str) #(pandas and Riley, 2021)\n",
    "df2020['R2'] = df2020['R2'].map(lambda x: x.replace('#',''))\n",
    "df2020['R2'] = df2020['R2'].map(lambda x: x.lstrip('nan'))#remove nan to convert back to number('int', 2021)\n",
    "df2020['R2'] = pd.to_numeric(df2020['R2'], errors='coerce')#back to numeric\n",
    "\n",
    "#and EOS points\n",
    "df2020['EOS'] = df2020['EOS'].astype(str) #(pandas and Riley, 2021)\n",
    "df2020['EOS'] = df2020['EOS'].map(lambda x: x.replace('#',''))\n",
    "df2020['EOS'] = df2020['EOS'].map(lambda x: x.lstrip('nan'))#remove nan to convert back to number('int', 2021)\n",
    "df2020['EOS'] = pd.to_numeric(df2020['EOS'], errors='coerce')#back to numeric\n",
    "\n",
    "#and Mid points\n",
    "df2020['Mid'] = df2020['Mid'].astype(str) #(pandas and Riley, 2021)\n",
    "df2020['Mid'] = df2020['Mid'].map(lambda x: x.replace('#',''))\n",
    "df2020['Mid'] = df2020['Mid'].map(lambda x: x.lstrip('nan'))#remove nan to convert back to number('int', 2021)\n",
    "df2020['Mid'] = pd.to_numeric(df2020['Mid'], errors='coerce')#back to numeric\n",
    "#debug\n",
    "#print(df2020['R2'].dtype)\n",
    "df2020.to_csv('data/2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b3c14-6ea2-43a5-80e2-bff46a50b24d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2bbffc-6ab1-4808-8842-9be1287da356",
   "metadata": {},
   "source": [
    "### 1.3 2019 CAO points\n",
    "http://www2.cao.ie/points/lvl8_19.pdf\n",
    "\n",
    "\n",
    "2019 CAO points are saved in a pdf file and tables within that file.\n",
    "Like 2021 L8 and Levels 6&7 are stored on two web pages (pdfs)\n",
    "For each pdf files: \n",
    "- the pdf is backed up\n",
    "- the file is opened in camelot and the contents of each pdf table is appened to a dataframe.\n",
    "- Columns are renamed and year column is added as and AQA, * and # are dealt with.\n",
    "- A regex function filters the dataframe to only hold courses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e1e1bc9-47dc-4249-86f1-b566a41626eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot #use camelot package to extract tables from pdf files [7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791d9f3-8511-44c9-bafd-e1cd86362b42",
   "metadata": {},
   "source": [
    "Read tables functions Parameters: url_path for path to read 2019 CAO points, csv_path to write to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1032e450-432b-4e46-a2a4-b4ced950fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read2019Tables(level):\n",
    "    #download url to path\n",
    "    # The file path for the url and csv/pdf saved file.\n",
    "    url_path='http://www2.cao.ie/points/lvl'+level+'_19.pdf'\n",
    "    csv_path = 'data/cao2019_L'+level+'_csv_' + nowstr + '.csv'\n",
    "    pdf_path = 'data/cao2019_L'+level+'_' + nowstr + '.pdf'\n",
    "  \n",
    "    #get the pdf and back it up\n",
    "    urlrq.urlretrieve(url_path,pdf_path)\n",
    "    #get the pdf tables o\n",
    "    #(Camelot: PDF Table Extraction for Humans — Camelot 0.10.1 documentation, 2021)\n",
    "    tables = camelot.read_pdf(url_path,\\\n",
    "                              pages='1-end',flavor='stream')\n",
    "   \n",
    "    #read all pages (Not able to read pdf tables spread across multiple pages · Issue #278 · atlanhq/camelot, 2021)  \n",
    "    #count tables and verify it matches the original file.\n",
    "    tbl_cnt = len(tables)\n",
    "    \n",
    "    tables[1].parsing_report\n",
    "    {\n",
    "        'accuracy': 99.02,\n",
    "        'whitespace': 12.24,\n",
    "        'order': 1,\n",
    "        'page': 10\n",
    "    }\n",
    "    \n",
    "    i = 1 # exclude first header table \n",
    "    #iterate through the list of tables \n",
    "    data2019 = [] # empty list of tables\n",
    "    for t in tables:    \n",
    "        if i > 0: #exclude 1st table\n",
    "            #write the table as a dataframe to listdata2019\n",
    "            data2019.append(t.df) \n",
    "        i +=1 \n",
    "\n",
    "    #combine all the dataframes in the list into one dataframe\n",
    "    dfcombined = pd.concat(data2019)\n",
    "\n",
    "    #add column headers\n",
    "    dfcombined.columns = ['Course Code', 'Course title', 'EOS', 'Mid']\n",
    "    #add year\n",
    "    dfcombined['Year']= '2019'\n",
    "    #add level\n",
    "    if url_path.find('l8') >= 0 :\n",
    "        \n",
    "        dfcombined['Level'] = '8'\n",
    "    elif url_path.find('l76') >= 0 :\n",
    "        dfcombined['Level'] = '6_7'\n",
    "    \n",
    "    tbl_cnt\n",
    "    #write to csv to store as back up.\n",
    "    dfcombined.to_csv(csv_path)\n",
    "    \n",
    "    return dfcombined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c62b689-4459-405c-adfd-e3cfe2ba6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function calls to read 2019 pdf files from website\n",
    "df2019L8=read2019Tables('76')\n",
    "df2019L67=read2019Tables('8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19a80d-a159-4dea-83e5-3aaa86ccee90",
   "metadata": {},
   "source": [
    "Filter df so only rows with course codes remain. (regex, Şirin and Siler, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a1f3e4d-d642-4ebf-b565-28e66c87b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter the dataframe on course code reg ex - i.e. get rid of institution title lines\n",
    "def regex_filter(val): \n",
    "    regex= '[A-Z]{2}[0-9]{3}'\n",
    "    if val:\n",
    "        mo = re.search(regex,val)\n",
    "        if mo:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d2edc4-0692-40c7-83f9-fee95501b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs2019 = [df2019L67,df2019L8]#place both dfs into a list\n",
    "df2019 = pd.concat(dfs2019,ignore_index=True) #concat dfs in list to make 1 df\n",
    "df2019 = df2019[df2019['Course Code'].apply(regex_filter)] #filter the dataframe on reg ex above\n",
    "#debug\n",
    "#df2019.to_csv('data/2019raw.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c26f3-8685-4e2d-a011-2c935e81787d",
   "metadata": {},
   "source": [
    "reset index to remove indexes from appended dataframes.\n",
    "reset because reindex will notwork with duplicate values indexes (Prasanna, 2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b05185f0-a776-42db-b606-e4a939b86d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2019 = df2019.reset_index(drop=True)\n",
    "\n",
    "#Create and set year column\n",
    "df2019['Year'] =2019\n",
    "\n",
    "#create columns for potfolio, AQA and random - signal 1 even though there is only 1 for 2019\n",
    "df2019['Rn1'] =''\n",
    "df2019['Po1'] =''\n",
    "df2019['AQA1'] =''\n",
    "#deal with random, portfolio and AQAs. These occur only in in the EOS field so check this field\n",
    "#for occurence, and strip out digits, replace digits and move flag to new column.\n",
    "#This done by passing df rows to helper functions\n",
    "#add HEI name #(How To Create a New Column Based on Values From Other Columns in Pandas, 2021)\n",
    "def HEIrow(row):\n",
    "    return getHEI(row['Course Code'])\n",
    "df2019['HEI'] = ''\n",
    "\n",
    "df2019['HEI'] = df2019.apply(lambda row: HEIrow(row), axis=1)\n",
    "\n",
    "def getRandomCol(row):\n",
    "    #treat this field as string\n",
    "    if row['EOS'].find('*') > -1:\n",
    "        return '*'\n",
    "df2019['Rn1'] =  df2019.apply(lambda row: getRandomCol(row), axis=1)\n",
    "\n",
    "def getPortFolCol(row):\n",
    "    if row['EOS'].find('#') > -1:\n",
    "        return '#'\n",
    "df2019['Po1'] =  df2019.apply(lambda row: getPortFolCol(row), axis=1)\n",
    "def getAQACol(row):\n",
    "    if row['EOS'].find('AQA') > -1:\n",
    "        return 'AQA'\n",
    "df2019['AQA1'] =  df2019.apply(lambda row: getAQACol(row), axis=1)\n",
    "#finally return digits if they exist to EOS\n",
    "def getDigitsCol(row):\n",
    "    points=''\n",
    "    for i in row['EOS']:\n",
    "            if i.isdigit():\n",
    "                #concat points string\n",
    "                points = points + i    \n",
    "    return points\n",
    "df2019['EOS'] =  df2019.apply(lambda row: getDigitsCol(row), axis=1)\n",
    "\n",
    "# clean '# +matric ' from Mid\n",
    "df2019['Mid'] = df2019['Mid'].astype(str) #(pandas and Riley, 2021)\n",
    "df2019['Mid'] = df2019['Mid'].map(lambda x: x.replace('# +matric ',''))\n",
    "df2019['Mid'] = df2019['Mid'].map(lambda x: x.lstrip('nan'))#remove nan to convert back to number('int', 2021)\n",
    "df2019['Mid'] = pd.to_numeric(df2019['Mid'], errors='coerce')#back to numeric\n",
    "\n",
    "\n",
    "#EOS has some blanks, convert to numeric or wont be treated as such\n",
    "df2019['EOS'] = pd.to_numeric(df2019['EOS'], errors='coerce')#back to numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "261a24bd-a5ab-4484-804f-e7e270e55ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to homogenise with 2020 and 2021\n",
    "df2019=df2019.rename(columns={'COURSE': 'Course title','Mid': 'Mid_19','EOS': 'EOS_19'})\n",
    "#debug\n",
    "#print(df2019)\n",
    "df2019.to_csv('data/2019.csv')\n",
    "#display (df2019.loc[df2019['Course Code']=='CK791']) #AL861,CK201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe2b00-b7a2-430f-8715-6837f915e84b",
   "metadata": {},
   "source": [
    "### 1.4 Join the data frames\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69f89bf4-1379-464d-bb57-f0065fd2b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "all_Courses = pd.DataFrame()\n",
    "dfs=[df2021,df2020,df2019]#(found, Hulsey and Hulsey, 2021)\n",
    "#join dfs\n",
    "all_Courses=pd.concat(dfs)\n",
    "\n",
    "#debug\n",
    "#all_Courses.to_csv('data/wholething.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "421b80b9-4e57-486f-b22a-81f754e0ff16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEI</th>\n",
       "      <th>Course Code</th>\n",
       "      <th>Course title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Level</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>Mid</th>\n",
       "      <th>EOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>AL801</td>\n",
       "      <td>Software Design for Virtual Reality and Gaming...</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>AL802</td>\n",
       "      <td>Software Design in Artificial Intelligence for...</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>313.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>AL803</td>\n",
       "      <td>Software Design for Mobile Apps and Connected ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>AL805</td>\n",
       "      <td>Computer Engineering for Network Infrastructur...</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>AL810</td>\n",
       "      <td>Quantity Surveying                            ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>Waterford Institute of Technology</td>\n",
       "      <td>WD188</td>\n",
       "      <td>Applied Health Care</td>\n",
       "      <td>2019</td>\n",
       "      <td>6_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>Waterford Institute of Technology</td>\n",
       "      <td>WD205</td>\n",
       "      <td>Molecular Biology with Biopharmaceutical Science</td>\n",
       "      <td>2019</td>\n",
       "      <td>6_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>Waterford Institute of Technology</td>\n",
       "      <td>WD206</td>\n",
       "      <td>Electronic Engineering</td>\n",
       "      <td>2019</td>\n",
       "      <td>6_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>Waterford Institute of Technology</td>\n",
       "      <td>WD207</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>2019</td>\n",
       "      <td>6_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>Waterford Institute of Technology</td>\n",
       "      <td>WD208</td>\n",
       "      <td>Manufacturing Engineering</td>\n",
       "      <td>2019</td>\n",
       "      <td>6_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4220 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    HEI Course Code  \\\n",
       "0       Athlone Institute of Technology       AL801   \n",
       "1       Athlone Institute of Technology       AL802   \n",
       "2       Athlone Institute of Technology       AL803   \n",
       "3       Athlone Institute of Technology       AL805   \n",
       "4       Athlone Institute of Technology       AL810   \n",
       "...                                 ...         ...   \n",
       "1386  Waterford Institute of Technology       WD188   \n",
       "1387  Waterford Institute of Technology       WD205   \n",
       "1388  Waterford Institute of Technology       WD206   \n",
       "1389  Waterford Institute of Technology       WD207   \n",
       "1390  Waterford Institute of Technology       WD208   \n",
       "\n",
       "                                           Course title  Year Level     R1  \\\n",
       "0     Software Design for Virtual Reality and Gaming...  2021     8  300.0   \n",
       "1     Software Design in Artificial Intelligence for...  2021     8  313.0   \n",
       "2     Software Design for Mobile Apps and Connected ...  2021     8  350.0   \n",
       "3     Computer Engineering for Network Infrastructur...  2021     8  321.0   \n",
       "4     Quantity Surveying                            ...  2021     8  328.0   \n",
       "...                                                 ...   ...   ...    ...   \n",
       "1386                                Applied Health Care  2019   6_7    NaN   \n",
       "1387   Molecular Biology with Biopharmaceutical Science  2019   6_7    NaN   \n",
       "1388                             Electronic Engineering  2019   6_7    NaN   \n",
       "1389                             Mechanical Engineering  2019   6_7    NaN   \n",
       "1390                          Manufacturing Engineering  2019   6_7    NaN   \n",
       "\n",
       "      R2  Mid  EOS  \n",
       "0    NaN  NaN  NaN  \n",
       "1    NaN  NaN  NaN  \n",
       "2    NaN  NaN  NaN  \n",
       "3    NaN  NaN  NaN  \n",
       "4    NaN  NaN  NaN  \n",
       "...   ..  ...  ...  \n",
       "1386 NaN  NaN  NaN  \n",
       "1387 NaN  NaN  NaN  \n",
       "1388 NaN  NaN  NaN  \n",
       "1389 NaN  NaN  NaN  \n",
       "1390 NaN  NaN  NaN  \n",
       "\n",
       "[4220 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Courses_Cols=all_Courses[['HEI','Course Code','Course title' ,'Year','Level','R1','R2','Mid','EOS']]\n",
    "all_Courses_Cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7dec84-cace-4ea2-a44b-478a93edfeac",
   "metadata": {},
   "source": [
    "---\n",
    "### 2 Annual CAO Pointa Comparions Using Pandas.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb67c382-52a9-4685-b079-df53ef89b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Throw everything out by year, twist flip, stretch it!\n",
    "#What are the categories? Year, HEI, L8 & L6/7 - should be able to infer 2020 levels for from 2019&2021  courses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d6276fb-d40a-42cf-9a72-3bb66075f44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356.1789007746219\n",
      "342.8391812865497\n",
      "426.4831223628692\n",
      "346.72714386959603\n",
      "426.4831223628692\n",
      "346.72714386959603\n"
     ]
    }
   ],
   "source": [
    "#debug:\n",
    "#print(all_Courses_Cols.dtypes)\n",
    "\n",
    "\n",
    "print(all_Courses_Cols['R1'].mean())\n",
    "print(all_Courses_Cols['R2'].mean())\n",
    "print(all_Courses_Cols['Mid'].mean())\n",
    "print(all_Courses_Cols['EOS'].mean())\n",
    "print(all_Courses_Cols['Mid'].mean())\n",
    "print(all_Courses_Cols['EOS'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ca95f90-9f05-4838-b98f-a148fb16e4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       300.0\n",
       "1       313.0\n",
       "2       350.0\n",
       "3       321.0\n",
       "4       328.0\n",
       "        ...  \n",
       "1386      NaN\n",
       "1387      NaN\n",
       "1388      NaN\n",
       "1389      NaN\n",
       "1390      NaN\n",
       "Name: R1, Length: 4220, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get statistical summary of each HEI\n",
    "CAOsummary_HEI=all_Courses_Cols.groupby('HEI').describe()\n",
    "#debug\n",
    "CAOsummary_HEI.to_csv('data/CAOsummaryHEI.csv')\n",
    "CAOsummaryYear=all_Courses_Cols.groupby('Year').describe()\n",
    "#debug\n",
    "CAOsummaryYear.to_csv('data/CAOsummaryYEAR.csv')\n",
    "#all_Courses_Cols.to_csv('data/all_data.csv')\n",
    "all_Courses_Cols[\"R1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586dcf7-29cb-42c6-a3a2-bb3531608aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(all_Courses_Cols[\"R1_21\"],all_Courses_Cols[\"Year\"])\n",
    "all_Courses_Cols['R1'].plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4e3b9-6cc3-4363-8704-efa0fb960d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAOsummary_HEI.reset_index(level=0, inplace=True)\n",
    "\n",
    "#CAOsummary_HEI\n",
    "#plt.bar(CAOsummary_HEI[\"mean\"],CAOsummary_HEI[\"HEI\"])\n",
    "plt.hist(all_Courses_Cols[\"HEI\"],all_Courses_Cols[\"R1\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f54e61-e864-4c03-a250-21e35d783f4b",
   "metadata": {},
   "source": [
    "---\n",
    "## References:\n",
    "\n",
    "Camelot-py.readthedocs.io. 2021. Camelot: PDF Table Extraction for Humans — Camelot 0.10.1 documentation. [online] Available at: <https://camelot-py.readthedocs.io/en/master/> [Accessed 23 November 2021].\n",
    "\n",
    "\n",
    " Hulsey, J. and Hulsey, J., 2021. How to iterate through a list of Data frames and drop all data if a specific string isnt found. [online] Stack Overflow. Available at: <https://stackoverflow.com/questions/55052989/how-to-iterate-through-a-list-of-data-frames-and-drop-all-data-if-a-specific-str> [Accessed 23 November 2021].\n",
    "\n",
    "Medium. 2021. How To Create a New Column Based on Values From Other Columns in Pandas. [online] Available at: <https://towardsdatascience.com/create-new-column-based-on-other-columns-pandas-5586d87de73d> [Accessed 23 November 2021].\n",
    "\n",
    "Medium. 2021. Check For a Substring in a Pandas DataFrame Column. [online] Available at: <https://towardsdatascience.com/check-for-a-substring-in-a-pandas-dataframe-column-4b949f64852> [Accessed 23 November 2021].\n",
    "\n",
    "\n",
    "upGrad blog. 2021. How to Implement Switch Case Functions in Python? [2021] | upGrad blog. [online] Available at: <https://www.upgrad.com/blog/how-to-implement-switch-case-functions-in-python/> [Accessed 23 November 2021].\n",
    "\n",
    "GitHub. 2021. Not able to read pdf tables spread across multiple pages · Issue #278 · atlanhq/camelot. [online] Available at: <https://github.com/atlanhq/camelot/issues/278> [Accessed 23 November 2021].\n",
    "\n",
    " Pandas.pydata.org. 2021. pandas.DataFrame — pandas 1.3.4 documentation. [online] Available at: <https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html> [Accessed 23 November 2021].\n",
    " \n",
    "Pandas.pydata.org. 2021. pandas.read_excel — pandas 1.3.4 documentation. [online] Available at: <https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html?highlight=read_excel#pandas.read_excel> [Accessed 23 November 2021].\n",
    "\n",
    " Pandas?, A., 2021. Appending to an empty DataFrame in Pandas?. [online] Stack Overflow. Available at: <https://stackoverflow.com/questions/16597265/appending-to-an-empty-dataframe-in-pandas> [Accessed 23 November 2021].\n",
    " \n",
    " Docs.python.org. 2021. re — Regular expression operations — Python 3.10.0 documentation. [online] Available at: <https://docs.python.org/3/library/re.html> [Accessed 23 November 2021].\n",
    " \n",
    " Stack Overflow. Available at: <https://stackoverflow.com/questions/15325182/how-to-filter-rows-in-pandas-by-regex/48884429> [Accessed 23 November 2021].\n",
    " \n",
    " Docs.python-requests.org. 2021. Requests: HTTP for Humans™ — Requests 2.26.0 documentation. [online] Available at: <https://docs.python-requests.org/en/latest/index.html> [Accessed 23 November 2021].\n",
    " \n",
    " R. and Prasanna, V., 2021. Right way to reindex a dataframe?. [online] Stack Overflow. Available at: <https://stackoverflow.com/questions/68261366/right-way-to-reindex-a-dataframe> [Accessed 23 November 2021].\n",
    " \n",
    " upGrad blog. 2021. How to Implement Switch Case Functions in Python? [2021] | upGrad blog. [online] Available at: <https://www.upgrad.com/blog/how-to-implement-switch-case-functions-in-python/> [Accessed 23 November 2021].\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0a441-8ac1-47c6-8749-afaf0be36292",
   "metadata": {
    "tags": []
   },
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8001c47-4497-4881-999a-bc7345b02440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "460de7e2-7470-45e3-8852-3c4827482701",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae013f-525c-4f19-8881-02fe1faf0345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1089c6-c888-4cc4-a165-3a900a9d0a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f502b3-920f-4ac1-a1dd-8f5d76d15a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e32f0d-8635-470f-a09d-846988570543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4554fdb-5290-44fd-b258-09c2b8f172b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a62d4-dd5b-4a23-9e5b-4c4ea05ef5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529df16-3b5c-4508-85df-17693bf30598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288606f-d160-496f-9d0b-bd86eec7a6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84384cbe-47c5-4e96-9e77-d6042c2ed461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
