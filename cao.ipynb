{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e8b6b3-4d32-44c2-a85f-e6da35747375",
   "metadata": {},
   "source": [
    "# A demonstration of PANDAS data frames used to investigate CAO points\n",
    "\n",
    "Author: Jon Ishaque\n",
    "Commenced: 29th September 2021\n",
    "GMIT SID: G00398244\n",
    "\n",
    "This notebook extracts CAO points from the CAO website for 2019, 2020 and 2021. It loads data into pandas dataframes and uses pandas and python to compare points from different years.\n",
    "\n",
    " Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    " \n",
    " \n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d53c1a-1d21-4ccf-8409-8e7480bf2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Package to make http requests\n",
    "import requests as rq\n",
    "\n",
    "# Dates and time package\n",
    "import datetime as dt\n",
    "\n",
    "#pandas to load data into dataframes and use functionality to manipulate data and analyse data\n",
    "import pandas as pd\n",
    "\n",
    "#import regex package for searching strings\n",
    "import re\n",
    "\n",
    "#import csv, deals with commas when writing to file\n",
    "import csv\n",
    "\n",
    "#use urlib to retrieve url as file for 2019 and 2020\n",
    "import urllib.request as urlrq "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717922c-6643-4593-a1fb-5814f3f194e6",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. Loading CAO data into pandas.\n",
    "\n",
    "Loading data into the notebook and pandas dataframes requires 3 different methods for each of the years 2019,2020 and 2021 because the data for each year is a different format for each year:\n",
    "\n",
    "2021 html webpage format\n",
    "\n",
    "2020 Microsoft Excel format\n",
    "\n",
    "2019 pdf\n",
    "\n",
    "The next state of the notebook will explain how each years CAO points are accessed from the CAO website, backed up locally in their original format and imported into a pandas dataframe for each year either directly or from a saved csv..\n",
    "\n",
    "The dataframes for each year are then joined up.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336fefee-76de-43b1-b5f3-377fcd3f791d",
   "metadata": {},
   "source": [
    "*** \n",
    "### 1.1 2021 points\n",
    "\n",
    "#http://www.cao.ie/index.php?page=points&p=2021\n",
    "The 2021 CAO points are presented in a web page. \n",
    "There are two pages one for level 6 & 7 and one for level 8.\n",
    "The web page are saved save files and loaded into a dataframe. \n",
    "\n",
    "The fucntion get2021() \n",
    "reads a webpage is accessed using the request library.\n",
    "Each line of the web page is read and tested for CAO course and points line\n",
    "with a regex. There are helper functions atomise fields into characters which may indicate, random selections and portfolio/interview assessment for courses. There is also a function to determing the institution form the course code. Each line is then written to a csv file.\n",
    "\n",
    "Both the level 6 & 7 and level 8 are then loaded into a single dataframe df2021\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b736154-d5d5-436d-82de-71eaadf116de",
   "metadata": {},
   "source": [
    "The page header from the server should decode as per: *Content-Type: text/html; charset=iso-8859-1*\n",
    "However, one line uses \\x96 which isn't defined in iso-8859-1. Therefore we use the similar decoding standard cp1252, which is very similar but includes #x96. The character in question was had an Irish foda on a level 8 course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace62ef-a7fc-4ecb-a031-85025c2fd75d",
   "metadata": {},
   "source": [
    "Create a string var,*now*. this is use in file names of back up copies of CAO points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1670e56-6d1f-41e0-82ab-48192b915c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date and time.\n",
    "\n",
    "now = dt.datetime.now()\n",
    "\n",
    "# Format as a string.\n",
    "#global as used in functions\n",
    "global nowstr\n",
    "nowstr = now.strftime('%Y%m%d_%H%M%S')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1c050-a5d7-435b-9a47-843528f77676",
   "metadata": {},
   "source": [
    "###### Compile the regular expression so it is not compiled at each interation of the loop reading the webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aaa91d-c89c-4a91-a669-e0e5829be163",
   "metadata": {},
   "source": [
    "###### Explanation of the regualar expression [4][5]:\n",
    "('[A-Z]{2}[0-9]{3} (.*)([0-9]{3}))</span>\n",
    "\n",
    "[A-Z]{2}        Any two upper case aphanumeric\n",
    "\n",
    "[0-9]{3}        Any three digits 0-9\n",
    "\n",
    "'  '            Two spaces\n",
    "\n",
    "(.*)([0-9]{3})   Any amount of text before 3 numeric characters\n",
    "\n",
    "\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78b1faf-cb9c-4494-9a9c-f19b73739946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set reg ex\n",
    "re_courses = re.compile('[A-Z]{2}[0-9]{3} (.*)') #[4]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4f57be-a30d-4221-94a5-610a6d31fb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to get HEI name from course code. using a switcher dict as\n",
    "#oppose to messy if/else block\n",
    "#https://www.upgrad.com/blog/how-to-implement-switch-case-functions-in-python/\n",
    "def getHEI(cc):\n",
    "    switcher = {'AC' : 'American College',\n",
    "    'AD' : 'National College of Art and Design',\n",
    "    'AL' : 'Athlone Institute of Technology',\n",
    "    'AS' : 'St. Angela`s College',\n",
    "    'CI' : 'Irish College of Humanities & Applied Sciences',\n",
    "    'BY' : 'IBAT College Dublin',\n",
    "    'CK' : 'University College Cork (NUI)',\n",
    "    'CM' : 'Marino Institute of Education',\n",
    "    'CR' : 'Cork Institute of Technology',\n",
    "    'CT' : 'CCT College Dublin',\n",
    "    'CW' : 'Institute of Technology Carlow',\n",
    "    'DB' : 'Dublin Business School',\n",
    "    'DC' : 'Dublin City University',\n",
    "    'DK' : 'Dundalk Institute of Technology',\n",
    "    'DL' : 'Dun Laoghaire Institute of Art Design and Technology',\n",
    "    'DN' : 'University College Dublin (NUI)',\n",
    "    'DS' : 'Dorset College',\n",
    "    'GA' : 'Galway-Mayo Institute of Technology',\n",
    "    'GB' : 'Galway Business School',\n",
    "    'GC' : 'Griffith College',\n",
    "    'GY' : 'National University of Ireland Galway',\n",
    "    'ID' : 'ICD Business School',\n",
    "    'LC' : 'Limerick Institute of Technology',\n",
    "    'LM' : 'University of Limerick',\n",
    "    'LY' : 'Letterkenny Institute of Technology',\n",
    "    'MH' : 'Maynooth University',\n",
    "    'MI' : 'Mary Immaculate College',\n",
    "    'MU' : 'Pontifical University St Patricks College',\n",
    "    'NC' : 'National College of Ireland (NCI)',\n",
    "    'NM' : 'St Nicholas Montessori College Ireland',\n",
    "    'PC' : 'Carlow College St. Patricks',\n",
    "    'RC' : 'RCSI University of Medicine & Health Sciences',\n",
    "    'SG' : 'Institute of Technology Sligo',\n",
    "    'TL' : 'Institute of Technology Tralee',\n",
    "    'TR' : 'Trinity College Dublin',\n",
    "    'TU' : 'Technological University Dublin',\n",
    "    'WD' : 'Waterford Institute of Technology'\n",
    "    }\n",
    "    cc = cc[:2]\n",
    "    return  switcher.get(cc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68bc80e0-02ce-43e7-a4be-75fc94bc72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper\n",
    "def points_to_arr(s):\n",
    "    AQA=''\n",
    "    portfolio =''\n",
    "    points=''\n",
    "    random = ''\n",
    "    #check 1st char for #\n",
    "    #print(s)\n",
    "    if s[0]=='#':\n",
    "        portfolio='#'# add to var\n",
    "    random = ''\n",
    "    #check final char for  *\n",
    "    if s[-1] == '*':\n",
    "        random ='*'\n",
    "    points=''    \n",
    "    if s.find(\"AQA\") ==-1: #not AQA\n",
    "        #strip ~ and * from start and end of s\n",
    "        for i in s:\n",
    "            if i.isdigit():\n",
    "                #concat points string\n",
    "                points = points + i\n",
    "    else:\n",
    "        AQA =\"AQA\" #return AQA as separate val as it will be separate column\n",
    "        #return\n",
    "    return [points, portfolio, random,AQA]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc2126-9021-4ecb-969e-a00939eb119b",
   "metadata": {},
   "source": [
    "The following block of code iterates through each line of the csv file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f644b8-b265-4f9f-99f2-b1f1d2060fbb",
   "metadata": {},
   "source": [
    "This part of the note part of the note book will load the web page content. A loop will read each line of web page and determine if it's content is relevant and write content to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a69844e-746d-4123-a633-6417ccb8f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get a save the csv names to paths\n",
    "global csv_files\n",
    "csv_files = []\n",
    "def get2021(path): #A function to create csv files from both the L6&7 and L8 webpages.\n",
    "    print (path)\n",
    "    #Get the both level 8 and 6/7 web pages\n",
    "    #getheaders and determine contenttype [3]\n",
    "    #respL8.headers['content-type']\n",
    "    #resp.text\n",
    "    #loop through response text lines\n",
    "    #get level\n",
    "    print (path)\n",
    "    if path.find('L8') >= 0 :\n",
    "        #print (path)\n",
    "        level = '8'\n",
    "        resp = rq.get('http://www2.cao.ie/points/l8.php',\n",
    "                      headers={\"content-type\":\"text\"})\n",
    "    elif path.find('L67') >= 0 :\n",
    "        #print (path)\n",
    "        level ='6/7'        \n",
    "        resp = rq.get('http://www2.cao.ie/points/l76.php', \n",
    "                      headers={\"content-type\":\"text\"})\n",
    "    else:\n",
    "        level = ''        \n",
    "    original_encoding = resp.encoding\n",
    "    # Change to cp1252, which handles accented characters\n",
    "    resp.encoding = 'cp1252'\n",
    "     # Create a file path for the original data. 2021\n",
    "    pathhtml = path + nowstr + '.html'\n",
    "    # Save the original html file.\n",
    "    with open(pathhtml, 'w') as f:\n",
    "        f.write(resp.text)\n",
    "    #set var to count lines for cross check with webpage\n",
    "    no_lines = 0\n",
    "    path = path+'.csv'\n",
    "    #add csv name to array so as to access when loading into df\n",
    "    csv_files.append(path)\n",
    "    with open(path, 'w') as f:\n",
    "        #write csv header\n",
    "        linesplit = ['Course Code','Course title','R1_21',\n",
    "                     'Po_1_21','Rn_1_21','AQA1_21','R2_21',\n",
    "                     'Po_2_21','Rn_2_21','AQA2_21',\n",
    "                     'HEI','Level','Year']\n",
    "        f.write(','.join(linesplit) + '\\n')\n",
    "        for line in resp.iter_lines():\n",
    "            #\n",
    "\n",
    "            #problem with bytes\n",
    "            #so convert str to bytes\n",
    "            #print (line)\n",
    "            dline = line.decode('cp1252')\n",
    "            #check if line mathces reg exp pattern. If so, do something.\n",
    "            if re_courses.fullmatch(dline):\n",
    "                no_lines +=1\n",
    "                #get first five chars - course code\n",
    "                course_code = dline[:5]\n",
    "                #course title\n",
    "                course_title = dline[7:57]\n",
    "                #r1 points\n",
    "                round_1 = dline[60:65].rstrip() # get five chars, remove white space\n",
    "                #if round 1 not blank call fn points_to_arr\n",
    "                if len(round_1) > 0:\n",
    "                    round_1= points_to_arr(round_1)\n",
    "                    #assign vals from returned array\n",
    "                    pts1 = round_1[0]\n",
    "                    plo1 = round_1[1]\n",
    "                    rnd1 = round_1[2]\n",
    "                    AQA1 = round_1[3]\n",
    "                else: \n",
    "                    pts1 = ''\n",
    "                    plo1 = ''\n",
    "                    rnd1 = ''\n",
    "                    AQA1 = ''\n",
    "                #r2 points\n",
    "                round_2 = dline[67:].rstrip() # get four chars, remove white space\n",
    "                #if round 2 not blank call fn points_to_arr\n",
    "                if len(round_2) > 0:\n",
    "                    round_2= points_to_arr(round_2)\n",
    "                    #assign vals from returned array\n",
    "                    pts2 = round_2[0]\n",
    "                    plo2 = round_2[1]\n",
    "                    rnd2 = round_2[2]\n",
    "                    AQA2 = round_2[3]\n",
    "                else: \n",
    "                    pts2 = ''\n",
    "                    plo2 = ''\n",
    "                    rnd2 = ''\n",
    "                    AQA2 = ''\n",
    "                #print (course_code)\n",
    "                #get the instituion name\n",
    "                HEI =getHEI(course_code)\n",
    "                #print (HEI)\n",
    "                # create an array of the fields for the csv line\n",
    "                linesplit = [course_code,course_title,pts1,plo1,rnd1,AQA2,pts2,plo2,rnd2,AQA2,HEI,level,'2021']\n",
    "                #print (linesplit)\n",
    "                #debug\n",
    "                #print(f\"'{course_code} {dline} r1: {round_1} r2: {round_2}'\")\n",
    "               # print((','.join(linesplit) + '\\n'))\n",
    "                # Rejoin the array values with commas in between. ie.comma separated\n",
    "                f.write(','.join(linesplit) + '\\n')\n",
    "    print (f\"number of lines is\", {no_lines})\n",
    "    path=''\n",
    "#check this number is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7746fce-9d1c-48bb-ad93-f4e8d46ca31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cao2021_L8_20211122_213030\n",
      "data/cao2021_L8_20211122_213030\n",
      "number of lines is {949}\n",
      "data/cao2021_L67_20211122_213030\n",
      "data/cao2021_L67_20211122_213030\n",
      "number of lines is {416}\n"
     ]
    }
   ],
   "source": [
    "# The file path for the csv file.\n",
    "path_2021_L8 = 'data/cao2021_L8_' + nowstr \n",
    "path_2021L67 ='data/cao2021_L67_' + nowstr \n",
    "\n",
    "get2021(path_2021_L8)\n",
    "get2021(path_2021L67)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c583d24-c845-47cd-a4a3-7daebabcf2f8",
   "metadata": {},
   "source": [
    "#### NB: 949 L8 courses on CAO website verified on 10th November 2021\n",
    "#### 416 L6/7 courses on CAO website verified on 15th November 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb331ea-4c98-44b7-81ff-ce8559b6067b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ea660-9a7c-436b-a22b-43dcca743b9a",
   "metadata": {},
   "source": [
    "Join L8 & L6/7 courses into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fa70f32-034d-43a6-94e0-ebbbc9397a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the list of csv files\n",
    "#https://stackoverflow.com/questions/16597265/appending-to-an-empty-dataframe-in-pandas\n",
    "\n",
    "#print(csv_files)\n",
    "df2021 = pd.DataFrame()\n",
    "for f in csv_files:      \n",
    "    # read the csv file with correc encoding\n",
    "    #print(f)\n",
    "    df_temp = pd.read_csv(f,encoding='cp1252') \n",
    "    df2021 = df2021.append(df_temp, ignore_index = True)\n",
    "\n",
    "\n",
    "#print(df2021)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a372d87-ba83-4a1c-9176-f61e5ca57396",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e55352-cc54-464f-95fe-3f46ccd224f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 2020 CAO points\n",
    "\n",
    "http://www.cao.ie/index.php?page=points&p=2020 \n",
    "The CAO points for 2020 stored in an excel(.xlss) file. All level courses were indcluded in the one file\n",
    "The excel file is downloaded using the urlrq package and backed up.\n",
    "The file is read then downloaded into a  pandas data frame df2020\n",
    "Some unwanted columns are deleted and columns are renamed for consistency with other years.\n",
    "*, AQA and # indicatores are pulled out using pandas functionality and written to new columns.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "359f5ab1-0128-41c5-8c24-fbc883961b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/cao2020_20211122_213030.xlsx',\n",
       " <http.client.HTTPMessage at 0x280674349a0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a file path for the original data.For backup\n",
    "path2020 = 'data/cao2020_' + nowstr + '.xlsx'\n",
    "\n",
    "#download to path\n",
    "urlrq.urlretrieve('http://www2.cao.ie/points/CAOPointsCharts2020.xlsx',\\\n",
    "                  path2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421cad63-4081-4846-9530-23f1a8cd2dd7",
   "metadata": {},
   "source": [
    "Read the Excel file into a pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e0b3820-bebf-4e9c-aa85-051e1572861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and parse the excel spreadsheet\n",
    "#skip first 10 header rows\n",
    "df2020=pd.read_excel('http://www2.cao.ie/points/CAOPointsCharts2020.xlsx',\\\n",
    "                 skiprows=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "421461f9-e63a-4423-a92b-8ec6241194aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[123]\n",
    "\n",
    "#check final row\n",
    "#delete unwanted columns\n",
    "df2020 = df2020.drop(['CATEGORY (i.e.ISCED description)','avp','v','Column1',\\\n",
    "              'Column2','Column3','Column4','Column5','Column6',\\\n",
    "              'Column7','Column8'], 1)\n",
    "#reaname columns \n",
    "df2020 = df2020.rename(columns={'COURSE TITLE': 'Course title',\\\n",
    "                        'COURSE CODE2': 'Course Code',\\\n",
    "                        'R1 POINTS':'R1_20','R2 POINTS':'R2_20',\\\n",
    "                        'R1 Random *':'Rn_1_20',\\\n",
    "                        'R2 Random*':'Rn_2_20','LEVEL':'Level',\\\n",
    "                        'EOS':'EOS_20','EOS Mid-point':'Mid_20'})\n",
    "#add some new columns\n",
    "df2020['Year'] =2020\n",
    "df2020['Po_1_20'] =''\n",
    "df2020['Po_2_20'] =''\n",
    "df2020['AQA1_20'] =''\n",
    "df2020['AQA2_20'] =''\n",
    "#https://towardsdatascience.com/check-for-a-substring-in-a-pandas-dataframe-column-4b949f64852\n",
    "\n",
    "#Pulling out AQA, # and  placing into own column.\n",
    "#this dataset has either digits or #matric code for portfolio and AQA. Check for value,\n",
    "#if it exists place in another column and set points col to blank.\n",
    "\n",
    "df2020.loc[df2020['R1_20'].str.contains('#',na=False) ,\\\n",
    "       'Po_1_20'] = '#' \n",
    "df2020.loc[df2020['R1_20'].str.contains('#',na=False) , 'R1_20'] = '' \n",
    "df2020.loc[df2020['R2_20'].str.contains('#',na=False) ,\\\n",
    "       'Po_2_20'] = '#' \n",
    "df2020.loc[df2020['R2_20'].str.contains('#',na=False) , 'R2_20'] = '' \n",
    "df2020.loc[df2020['R1_20'].str.contains('AQA',na=False) , 'AQA1'] = 'AQA' \n",
    "df2020.loc[df2020['R2_20'].str.contains('AQA',na=False) , 'AQA2'] = '' \n",
    "#display (df2020.loc[df2020['Course Code']=='CR210']) # check we are picking up commas in csv fields          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b3c14-6ea2-43a5-80e2-bff46a50b24d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2bbffc-6ab1-4808-8842-9be1287da356",
   "metadata": {},
   "source": [
    "### 1.3 2019 CAO points\n",
    "http://www2.cao.ie/points/lvl8_19.pdf\n",
    "\n",
    "\n",
    "2019 CAO points are saved in a pdf file and tables within that file.\n",
    "Like 2021 L8 and Levels 6&7 are stored on two web pages (pdfs)\n",
    "For each pdf files: \n",
    "- the pdf is backed up\n",
    "- the file is opened in camelot and the contents of each pdf table is appened to a dataframe.\n",
    "- Columns are renameds year column is added as and AQA, * and # are dealt with.\n",
    "- A regfunction filters the dataframe to only hold courses.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e1e1bc9-47dc-4249-86f1-b566a41626eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot #use camelot package to extract tables from pdf files [7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791d9f3-8511-44c9-bafd-e1cd86362b42",
   "metadata": {},
   "source": [
    "Read tables functions Parameters: url_path for path to read 2019 CAO points, csv_path to write to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1032e450-432b-4e46-a2a4-b4ced950fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTables(level):\n",
    "    #download url to path\n",
    "    # The file path for the url and csv/pdf saved file.\n",
    "    url_path='http://www2.cao.ie/points/lvl'+level+'_19.pdf'\n",
    "    csv_path = 'data/cao2019_L'+level+'_csv_' + nowstr + '.csv'\n",
    "    pdf_path = 'data/cao2019_L'+level+'_' + nowstr + '.csv'\n",
    "  \n",
    "    #get the pdf and back it up\n",
    "    urlrq.urlretrieve(url_path,pdf_path)\n",
    "    #get the pdf tables o\n",
    "    tables = camelot.read_pdf(url_path,\\\n",
    "                              pages='1-end',flavor='stream')\n",
    "   \n",
    "    #read all pages [8]\n",
    "    tables\n",
    "    #count tables and verify it matches the original file.\n",
    "    tbl_cnt = len(tables)\n",
    "    #export all tables - not what we really want\n",
    "    #tables.export(path, f='csv', compress=False) \n",
    "    #tables[0]\n",
    "    tables[1].parsing_report\n",
    "    {\n",
    "        'accuracy': 99.02,\n",
    "        'whitespace': 12.24,\n",
    "        'order': 1,\n",
    "        'page': 10\n",
    "    }\n",
    "    \n",
    "    i = 1 # exclude first header table \n",
    "    #interate through the list of tables [9] \n",
    "    data2019 = [] # empty list of tables\n",
    "\n",
    "    for t in tables:    \n",
    "        if i > 0: #exclude 1st table\n",
    "            #write the table as a dataframe to listdata2019\n",
    "            data2019.append(t.df) \n",
    "        i +=1 \n",
    "\n",
    "    #combine all the dataframes in the list into one dataframe\n",
    "    dfcombined = pd.concat(data2019)\n",
    "\n",
    "    #add column headers\n",
    "    dfcombined.columns = ['Course Code', 'Course title', 'EOS', 'Mid']\n",
    "    #add year\n",
    "    dfcombined['Year']= '2019'\n",
    "    #add level\n",
    "    if url_path.find('l8') >= 0 :\n",
    "        \n",
    "        dfcombined['Level'] = '8'\n",
    "    elif url_path.find('l76') >= 0 :\n",
    "        dfcombined['Level'] = '8'\n",
    "    \n",
    "    tbl_cnt\n",
    "    #write to csv to store as back up.\n",
    "    dfcombined.to_csv(csv_path)\n",
    "    \n",
    "    return dfcombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c62b689-4459-405c-adfd-e3cfe2ba6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function calls to read 2019 pdf files from website\n",
    "df2019L8=readTables('76')\n",
    "df2019L67=readTables('8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19a80d-a159-4dea-83e5-3aaa86ccee90",
   "metadata": {},
   "source": [
    "Filter df so only rows with course codes remain. [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f3e4d-d642-4ebf-b565-28e66c87b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter the dataframe on course code reg ex - i.e. get rid of institution title lines\n",
    "def regex_filter(val): \n",
    "    regex= '[A-Z]{2}[0-9]{3}'\n",
    "    if val:\n",
    "        mo = re.search(regex,val)\n",
    "        if mo:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2edc4-0692-40c7-83f9-fee95501b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs2019 = [df2019L67,df2019L8]\n",
    "df2019 = pd.concat(dfs2019,ignore_index=True)\n",
    "df2019 = df2019[df2019['Course Code'].apply(regex_filter)] #filter the dataframe on reg ex above\n",
    "df2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c26f3-8685-4e2d-a011-2c935e81787d",
   "metadata": {},
   "source": [
    "###### reset index to remove indexes from appended dataframes.\n",
    "reset because reindex will notwork with duplicate values indexes [11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05185f0-a776-42db-b606-e4a939b86d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2019 = df2019.reset_index(drop=True)\n",
    "#Create and set year column\n",
    "df2019['Year'] =2019\n",
    "#create columns for potfolio, AQA and random - signal 1 even though there only 1 for 2019\n",
    "df2019['Rn1_19'] =''\n",
    "df2019['Po_1_19'] =''\n",
    "df2019['AQA1_19'] =''\n",
    "\n",
    "\n",
    "\n",
    "#deal with random, portfolio and AQAs. These occur only in in the EOS field so check this field\n",
    "#for occurence, and strip out digits, replace digits and move flag to new column.\n",
    "#This done by passing df rows to helper functions\n",
    "#\n",
    "#add HEI name #https://towardsdatascience.com/create-new-column-based-on-other-columns-pandas-5586d87de73d\n",
    "def HEIrow(row):\n",
    "    return getHEI(row['Course Code'])\n",
    "df2019['HEI'] = ''\n",
    "\n",
    "df2019['HEI'] = df2019.apply(lambda row: HEIrow(row), axis=1)\n",
    "\n",
    "def getRandomCol(row):\n",
    "    #treat this field as string\n",
    "    if row['EOS'].find('*') > -1:\n",
    "        return '*'\n",
    "df2019['Rn_1_19'] =  df2019.apply(lambda row: getRandomCol(row), axis=1)\n",
    "\n",
    "def getPortFolCol(row):\n",
    "    if row['EOS'].find('#') > -1:\n",
    "        return '#'\n",
    "df2019['Po_1_19'] =  df2019.apply(lambda row: getPortFolCol(row), axis=1)\n",
    "def getAQACol(row):\n",
    "    if row['EOS'].find('AQA') > -1:\n",
    "        return 'AQA'\n",
    "df2019['AQA1_19'] =  df2019.apply(lambda row: getAQACol(row), axis=1)\n",
    "#finally return digits if they exist to EOS\n",
    "def getDigitsCol(row):\n",
    "    points=''\n",
    "    for i in row['EOS']:\n",
    "            if i.isdigit():\n",
    "                #concat points string\n",
    "                points = points + i    \n",
    "    return points\n",
    "df2019['EOS'] =  df2019.apply(lambda row: getDigitsCol(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a24bd-a5ab-4484-804f-e7e270e55ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019=df2019.rename(columns={'COURSE': 'Course title','Mid': 'Mid_2019','EOS': 'EOS_2019'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3b68c-e330-485c-a0a3-b88c254c69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "display (df2019.loc[df2019['Course Code']=='CK791']) #AL861,CK201\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93af45-7cb5-4b7b-aa81-439c04f2d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get unique course list\n",
    "#Create short dataframes\n",
    "df2019_sh = df2019[['Course Code','Course title','Level']]\n",
    "df2020_sh = df2020[['Course Code','Course title','Level']]\n",
    "df2021_sh = df2021[['Course Code','Course title','Level']]\n",
    "#display(df2021_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e32938-dff2-4090-9185-d89c8aa33e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[df2021_sh,df2020_sh,df2021_sh]\n",
    "all_Courses=pd.concat(dfs,ignore_index=True)\n",
    "#all_Courses[all_Courses.duplicated(subset=['Course code'])]\n",
    "#clean date, remove duplicates on course code\n",
    "\n",
    "all_Courses.drop_duplicates(subset=['Course Code'],inplace=True,ignore_index=False)\n",
    "\n",
    "all_Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1cb46-b928-482e-bcd7-ba99a7d26eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "#display (all_Courses.loc[all_Courses['Course code']=='WD208'])\n",
    "#all_Courses.iloc[1538]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe2b00-b7a2-430f-8715-6837f915e84b",
   "metadata": {},
   "source": [
    "### 1.4 Join the data frames\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49137dcf-7c74-4ef3-8edc-842718e4a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set course code as index - default column to join frame on, makes the code much cleaner.\n",
    "df2019.set_index('Course Code',inplace=True)\n",
    "df2020.set_index('Course Code',inplace=True)\n",
    "df2021.set_index('Course Code',inplace=True)\n",
    "all_Courses.set_index('Course Code',inplace=True)\n",
    "\n",
    "all_Courses=all_Courses.join(df2021[['R1_21','Rn_1_21','Po_1_21','AQA1_21','R2_21','Rn_2_21','Po_2_21','AQA2_21']])\n",
    "all_Courses=all_Courses.join(df2020[['R1_20','Rn_1_20','Po_1_20','AQA1_20','R2_20','Rn_2_20','Po_2_20','AQA2_20']])\n",
    "all_Courses=all_Courses.join(df2019[['Rn_1_19','Po_1_19','AQA1_19','EOS_2019','Mid_2019']])\n",
    "all_Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b80b9-4e57-486f-b22a-81f754e0ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Courses_usefulCols=all_Courses[['Course title' ,'Level','R1_21','R2_21','R1_20','R2_20']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6761c2fd-df61-4055-8b53-351aec396c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Courses_usefulCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7e15d7-8980-4a69-ac8f-2eb8aadbef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Courses_usefulCols['R2_21']=all_Courses_usefulCols['R2_21'].fillna(0)\n",
    "\n",
    "all_Courses_usefulCols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6a072-493a-4d2f-a262-9a23c2821365",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_Courses_usefulCols.convert_dtypes(infer_objects=False).dtypes \n",
    "all_Courses_usefulCols['R1_21'] = all_Courses_usefulCols['R1_21'].astype(int)\n",
    "all_Courses_usefulCols.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f54e61-e864-4c03-a250-21e35d783f4b",
   "metadata": {},
   "source": [
    "---\n",
    "## References:\n",
    "[1]\n",
    "\n",
    "[2]\n",
    "\n",
    "[3] https://docs.python-requests.org/en/latest/index.html\n",
    "\n",
    "[4] https://docs.python.org/3/library/re.html\n",
    "\n",
    "[5] https://docs.python.org/3/library/re.html?highlight=re%20match#re.match\n",
    "\n",
    "[6] https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html?highlight=read_excel#pandas.read_excel\n",
    "\n",
    "[7] https://camelot-py.readthedocs.io/en/master/\n",
    "\n",
    "[8] https://github.com/atlanhq/camelot/issues/278\n",
    "\n",
    "[9] https://stackoverflow.com/questions/55052989/how-to-iterate-through-a-list-of-data-frames-and-drop-all-data-if-a-specific-str\n",
    "\n",
    "[10] https://stackoverflow.com/questions/15325182/how-to-filter-rows-in-pandas-by-regex/48884429\n",
    "\n",
    "[11] https://stackoverflow.com/questions/68261366/right-way-to-reindex-a-dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0a441-8ac1-47c6-8749-afaf0be36292",
   "metadata": {
    "tags": []
   },
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8001c47-4497-4881-999a-bc7345b02440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e25795-04b7-4f77-b49b-8c578449703d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae013f-525c-4f19-8881-02fe1faf0345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1089c6-c888-4cc4-a165-3a900a9d0a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f502b3-920f-4ac1-a1dd-8f5d76d15a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e32f0d-8635-470f-a09d-846988570543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4554fdb-5290-44fd-b258-09c2b8f172b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a62d4-dd5b-4a23-9e5b-4c4ea05ef5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529df16-3b5c-4508-85df-17693bf30598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288606f-d160-496f-9d0b-bd86eec7a6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84384cbe-47c5-4e96-9e77-d6042c2ed461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
